{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttntbn/Deep-Learning/blob/main/real_Helmet_Detection_using_Faster_RCNN_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8751e92",
      "metadata": {
        "id": "b8751e92"
      },
      "source": [
        "# Helmet Detection with Faster R-CNN — Clean Notebook (ไทย)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0620815",
      "metadata": {
        "id": "a0620815"
      },
      "source": [
        "เวอร์ชันนี้จัดระเบียบใหม่ให้ **อ่านง่าย**, **แก้ไขสะดวก**, และ **เทรนพร้อมกราฟ loss สด**\n",
        "- รวม **hyperparameters** ไว้ในที่เดียว\n",
        "- คอมเมนต์ไทยอธิบายทุกส่วน: Config → Data → Transforms → Dataloaders → Model → Train → Save\n",
        "- เทรนแล้วเห็นกราฟ Loss ต่อ step แบบ Live"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b62ec0",
      "metadata": {
        "id": "91b62ec0"
      },
      "source": [
        "## 1) Config — ปรับค่าที่นี่เพื่อคุมการเทรน"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523c5603",
      "metadata": {
        "id": "523c5603"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Configurable Hyperparameters\n",
        "# ==============================\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Paths (แก้ให้ตรงกับเครื่อง) ---\n",
        "DATA_ROOT   = Path(\"/content/drive/MyDrive/helmet_dataset\")   # โฟลเดอร์หลักของรูป/annotations\n",
        "TRAIN_IMG   = DATA_ROOT / \"train/images\"\n",
        "TRAIN_ANN   = DATA_ROOT / \"train/annotations\"   # VOC XML\n",
        "VAL_IMG     = DATA_ROOT / \"val/images\"\n",
        "VAL_ANN     = DATA_ROOT / \"val/annotations\"\n",
        "OUTPUT_DIR  = Path(\"./outputs_frcnn\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Classes (แก้ให้ตรงกับชุดข้อมูล) ---\n",
        "# ตัวอย่าง: 2 คลาส + background\n",
        "CLASSES = [\"__background__\", \"helmet\", \"no_helmet\"]\n",
        "\n",
        "# --- Training hyperparams ---\n",
        "EPOCHS        = 15\n",
        "BATCH_SIZE    = 8\n",
        "LR            = 5e-4\n",
        "WEIGHT_DECAY  = 1e-4\n",
        "MOMENTUM      = 0.9\n",
        "WARMUP_STEPS  = 500\n",
        "\n",
        "# --- LR scheduler options ---\n",
        "LR_SCHEDULER  = \"multistep\"     # [\"none\", \"multistep\", \"cosine\"]\n",
        "MILESTONES    = [10, 15]\n",
        "GAMMA         = 0.1\n",
        "COSINE_TMAX   = EPOCHS\n",
        "ETA_MIN       = 1e-6\n",
        "\n",
        "# --- Data Augmentations ---\n",
        "H_FLIP_PROB   = 0.5\n",
        "RAND_RESIZE   = (640, 1024)\n",
        "COLOR_JITTER  = True\n",
        "\n",
        "SEED          = 1337\n",
        "\n",
        "print(\"OUTPUT_DIR:\", OUTPUT_DIR.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa6547c",
      "metadata": {
        "id": "efa6547c"
      },
      "source": [
        "## 2) Setup — ไลบรารีและอุปกรณ์"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== run this FIRST (top of notebook, before importing torch) =====\n",
        "!pip -q install comet-ml\n",
        "\n",
        "import os\n",
        "# ใส่ค่า \"จริง\" ของคุณ (หรือใช้ environment variables ก็ได้)\n",
        "os.environ[\"COMET_API_KEY\"]      = \"KlDdmMhprhNGWTot1PPhnMo4u\"             # คีย์จริงจาก Account Settings\n",
        "os.environ[\"COMET_WORKSPACE\"]    = \"boonyapon-boontub-0272\"     # <- จากลิงก์ของคุณ\n",
        "os.environ[\"COMET_PROJECT_NAME\"] = \"helmet-fasterrcnn\"\n",
        "\n",
        "from comet_ml import Experiment\n",
        "\n",
        "experiment = Experiment(\n",
        "    api_key=os.getenv(\"COMET_API_KEY\"),\n",
        "    workspace=os.getenv(\"COMET_WORKSPACE\"),\n",
        "    project_name=os.getenv(\"COMET_PROJECT_NAME\"),\n",
        "    auto_metric_logging=False,\n",
        "    auto_param_logging=False,\n",
        "    auto_output_logging=\"simple\",\n",
        ")\n",
        "experiment.set_name(\"fasterrcnn-helmet-run\")\n"
      ],
      "metadata": {
        "id": "qaClxPj_rTxB"
      },
      "id": "qaClxPj_rTxB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0a544e8",
      "metadata": {
        "id": "d0a544e8"
      },
      "outputs": [],
      "source": [
        "import os, math, time, random, xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import torch, torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# reproducibility\n",
        "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea1fa588",
      "metadata": {
        "id": "ea1fa588"
      },
      "source": [
        "## 3) Dataset (VOC XML) — อ่านกล่องจากไฟล์ .xml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e052626",
      "metadata": {
        "id": "4e052626"
      },
      "outputs": [],
      "source": [
        "def _read_voc_xml(xml_path, class_to_idx):\n",
        "    # อ่าน annotation แบบ VOC XML -> boxes, labels (index เริ่ม 1 สำหรับคลาสของเรา)\n",
        "    tree = ET.parse(str(xml_path))\n",
        "    root = tree.getroot()\n",
        "    boxes, labels = [], []\n",
        "    for obj in root.findall(\"object\"):\n",
        "        name = obj.find(\"name\").text.strip()\n",
        "        if name not in class_to_idx:\n",
        "            continue\n",
        "        bnd = obj.find(\"bndbox\")\n",
        "        x1 = float(bnd.find(\"xmin\").text); y1 = float(bnd.find(\"ymin\").text)\n",
        "        x2 = float(bnd.find(\"xmax\").text); y2 = float(bnd.find(\"ymax\").text)\n",
        "        if x2 <= x1 or y2 <= y1:   # กรองกล่องผิดรูป\n",
        "            continue\n",
        "        boxes.append([x1, y1, x2, y2])\n",
        "        labels.append(class_to_idx[name])\n",
        "    return boxes, labels\n",
        "\n",
        "class HelmetVOCDataset(data.Dataset):\n",
        "    # จับคู่รูปใน IMG_DIR กับไฟล์ XML ใน ANN_DIR ชื่อเดียวกัน\n",
        "    def __init__(self, img_dir: Path, ann_dir: Path, classes, transforms=None):\n",
        "        self.img_dir = Path(img_dir); self.ann_dir = Path(ann_dir)\n",
        "        self.transforms = transforms; self.classes = classes\n",
        "        # mapping ชื่อคลาส -> index เริ่ม 1 (0 = background)\n",
        "        self.class_to_idx = {}; idx = 1\n",
        "        for c in classes:\n",
        "            if c == \"__background__\": continue\n",
        "            self.class_to_idx[c] = idx; idx += 1\n",
        "        # list รูปที่มี XML คู่กัน\n",
        "        exts = {\".jpg\",\".jpeg\",\".png\"}; items = []\n",
        "        for p in sorted(self.img_dir.iterdir()):\n",
        "            if p.suffix.lower() in exts:\n",
        "                xml = self.ann_dir / (p.stem + \".xml\")\n",
        "                if xml.exists():\n",
        "                    items.append((p, xml))\n",
        "        self.items = items\n",
        "\n",
        "    def __len__(self): return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, xml_path = self.items[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        boxes, labels = _read_voc_xml(xml_path, self.class_to_idx)\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,4), dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)  if labels else torch.zeros((0,), dtype=torch.int64)\n",
        "        target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": torch.tensor([idx])}\n",
        "        if self.transforms is not None: img, target = self.transforms(img, target)\n",
        "        return img, target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb6fafa",
      "metadata": {
        "id": "1eb6fafa"
      },
      "source": [
        "### Transforms — Augmentations เพื่อลด overfit / เพิ่มความทนทาน"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34171926",
      "metadata": {
        "id": "34171926"
      },
      "outputs": [],
      "source": [
        "class ComposeTransforms:\n",
        "    def __init__(self, transforms): self.transforms = transforms\n",
        "    def __call__(self, img, target):\n",
        "        for t in self.transforms: img, target = t(img, target)\n",
        "        return img, target\n",
        "\n",
        "class RandomHorizontalFlip:\n",
        "    def __init__(self, p=0.5): self.p = p\n",
        "    def __call__(self, img, target):\n",
        "        if random.random() < self.p:\n",
        "            w, h = img.size; img = F.hflip(img)\n",
        "            boxes = target[\"boxes\"]\n",
        "            if boxes.numel() > 0:\n",
        "                x1 = w - boxes[:,2]; x2 = w - boxes[:,0]\n",
        "                boxes[:,0] = x1; boxes[:,2] = x2\n",
        "                target[\"boxes\"] = boxes\n",
        "        return img, target\n",
        "\n",
        "class RandomResizeLongestSide:\n",
        "    # resize ให้ด้านยาวสุ่มในช่วง RAND_RESIZE (รักษาอัตราส่วนภาพ)\n",
        "    def __init__(self, min_long, max_long):\n",
        "        self.min_long = min_long; self.max_long = max_long\n",
        "    def __call__(self, img, target):\n",
        "        w, h = img.size; long_side = max(w, h)\n",
        "        new_long = random.randint(self.min_long, self.max_long)\n",
        "        scale = new_long / long_side\n",
        "        new_w, new_h = int(w*scale), int(h*scale)\n",
        "        img = F.resize(img, [new_h, new_w])\n",
        "        boxes = target[\"boxes\"]\n",
        "        if boxes.numel()>0:\n",
        "            boxes = boxes * scale; target[\"boxes\"] = boxes\n",
        "        return img, target\n",
        "\n",
        "class OptionalColorJitter:\n",
        "    def __init__(self, enable=True):\n",
        "        self.enable = enable\n",
        "        self.jitter = T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02)\n",
        "    def __call__(self, img, target):\n",
        "        if self.enable: img = self.jitter(img)\n",
        "        return img, target\n",
        "\n",
        "def make_transforms(train=True):\n",
        "    tsfms = []\n",
        "    if train:\n",
        "        tsfms += [RandomResizeLongestSide(RAND_RESIZE[0], RAND_RESIZE[1]),\n",
        "                  RandomHorizontalFlip(H_FLIP_PROB),\n",
        "                  OptionalColorJitter(COLOR_JITTER)]\n",
        "    else:\n",
        "        tsfms += [RandomResizeLongestSide(RAND_RESIZE[0], RAND_RESIZE[1])]\n",
        "    def to_tensor(img, target): return F.to_tensor(img), target\n",
        "    tsfms += [to_tensor]\n",
        "    return ComposeTransforms(tsfms)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df2167bb",
      "metadata": {
        "id": "df2167bb"
      },
      "source": [
        "## 4) Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lwsKdJDjEEhb"
      },
      "id": "lwsKdJDjEEhb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54b964d",
      "metadata": {
        "id": "a54b964d"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/helmet_dataset\")\n",
        "TRAIN_IMG_DIR = DATA_ROOT / \"train/images\"\n",
        "TRAIN_ANN_DIR = DATA_ROOT / \"train/annotations\"\n",
        "VAL_IMG_DIR   = DATA_ROOT / \"val/images\"\n",
        "VAL_ANN_DIR   = DATA_ROOT / \"val/annotations\"\n",
        "\n",
        "def _count(p, exts):\n",
        "    return sum(1 for q in p.iterdir() if q.is_file() and q.suffix.lower() in exts)\n",
        "\n",
        "# เช็คมีโฟลเดอร์จริง\n",
        "for p in [TRAIN_IMG_DIR, TRAIN_ANN_DIR, VAL_IMG_DIR, VAL_ANN_DIR]:\n",
        "    assert p.exists(), f\"ไม่พบโฟลเดอร์: {p}\"\n",
        "\n",
        "print(\"train:\", _count(TRAIN_IMG_DIR,{'.jpg','.jpeg','.png'}),\"images /\",\n",
        "      _count(TRAIN_ANN_DIR,{'.xml'}),\"xml\")\n",
        "print(\"val  :\", _count(VAL_IMG_DIR,  {'.jpg','.jpeg','.png'}),\"images /\",\n",
        "      _count(VAL_ANN_DIR,  {'.xml'}),\"xml\")\n",
        "\n",
        "# collate_fn (ถ้ายังไม่ได้ประกาศ)\n",
        "try:\n",
        "    collate_fn  # noqa: F821\n",
        "except NameError:\n",
        "    def collate_fn(batch):\n",
        "        imgs, tgts = list(zip(*batch))\n",
        "        return list(imgs), list(tgts)\n",
        "\n",
        "# Datasets & Dataloaders\n",
        "train_ds = HelmetVOCDataset(TRAIN_IMG_DIR, TRAIN_ANN_DIR, CLASSES, transforms=make_transforms(train=True))\n",
        "val_ds   = HelmetVOCDataset(VAL_IMG_DIR,   VAL_ANN_DIR,   CLASSES, transforms=make_transforms(train=False))\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "    num_workers=2, pin_memory=True, prefetch_factor=2,\n",
        "    persistent_workers=False,   # <- เปลี่ยนจาก True เป็น False\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=1, shuffle=False,\n",
        "    num_workers=2, pin_memory=True, prefetch_factor=2,\n",
        "    persistent_workers=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "\n",
        "print(\"OK -> loaders ready | train:\", len(train_ds), \"| val:\", len(val_ds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47a60a03",
      "metadata": {
        "id": "47a60a03"
      },
      "source": [
        "## 5) Model — Faster R-CNN ResNet50 FPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3437656b",
      "metadata": {
        "id": "3437656b"
      },
      "outputs": [],
      "source": [
        "def build_model(num_classes: int):\n",
        "    model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "    in_feats = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_feats, num_classes)\n",
        "    return model\n",
        "\n",
        "model = build_model(num_classes=len(CLASSES)).to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e57894fc",
      "metadata": {
        "id": "e57894fc"
      },
      "source": [
        "## 6) Optimizer & LR Scheduler — พร้อม Linear Warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c83786",
      "metadata": {
        "id": "d5c83786"
      },
      "outputs": [],
      "source": [
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "if LR_SCHEDULER == \"multistep\":\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "elif LR_SCHEDULER == \"cosine\":\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=COSINE_TMAX, eta_min=ETA_MIN)\n",
        "else:\n",
        "    scheduler = None\n",
        "\n",
        "global_step = 0\n",
        "\n",
        "def set_lr(opt, lr):\n",
        "    for g in opt.param_groups: g['lr'] = lr\n",
        "\n",
        "def get_warmup_lr(base_lr, step, warmup_steps):\n",
        "    if warmup_steps <= 0: return base_lr\n",
        "    return base_lr * min(1.0, step / float(warmup_steps))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== core training setup =====\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(\n",
        "    [p for p in model.parameters() if p.requires_grad],\n",
        "    lr=LR,\n",
        "    momentum=MOMENTUM,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "\n",
        "# scheduler (เลือกตามค่าที่ตั้งไว้)\n",
        "if LR_SCHEDULER == \"multistep\":\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer, milestones=MILESTONES, gamma=GAMMA\n",
        "    )\n",
        "elif LR_SCHEDULER == \"cosine\":\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=COSINE_TMAX, eta_min=ETA_MIN\n",
        "    )\n",
        "else:  # \"none\"\n",
        "    scheduler = None\n",
        "\n",
        "# ถ้ายังไม่ได้ประกาศ global_step\n",
        "try:\n",
        "    global_step\n",
        "except NameError:\n",
        "    global_step = 0\n"
      ],
      "metadata": {
        "id": "KOeV78g2toj9"
      },
      "id": "KOeV78g2toj9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_epoch_plot():\n",
        "    \"\"\"อัปเดตกราฟราย epoch (train/val) แบบเดียวกับโค้ด MNIST\"\"\"\n",
        "    x = np.arange(1, len(train_epoch_loss) + 1)\n",
        "\n",
        "    # อัปเดตเส้น\n",
        "    tr_line.set_data(x, train_epoch_loss)\n",
        "    va_line.set_data(x, val_epoch_loss)\n",
        "\n",
        "    # กำหนดขอบแกน X\n",
        "    ax_ep.set_xlim(1, max(5, len(train_epoch_loss) + 0.5))\n",
        "\n",
        "    # กำหนดขอบแกน Y จากค่าที่มีทั้งหมด\n",
        "    if train_epoch_loss or val_epoch_loss:\n",
        "        y_all = (train_epoch_loss or []) + (val_epoch_loss or [])\n",
        "        y_min, y_max = float(min(y_all)), float(max(y_all))\n",
        "        if y_max == y_min:\n",
        "            y_max += 1.0\n",
        "            y_min -= 1.0\n",
        "        margin = 0.1 * (y_max - y_min)\n",
        "        ax_ep.set_ylim(y_min - margin, y_max + margin)\n",
        "\n",
        "    # วาดและอัปเดตเฟรมเดิมใน Colab\n",
        "    fig_ep.canvas.draw()\n",
        "    try:\n",
        "        ep_handle.update(fig_ep)  # ต้องมี display(fig_ep, display_id=True) มาก่อน\n",
        "    except Exception:\n",
        "        display(fig_ep)\n"
      ],
      "metadata": {
        "id": "hiUZUJFcv8oH"
      },
      "id": "hiUZUJFcv8oH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== สร้างกราฟ epoch (train vs val) เพื่ออัปเดตใน cell เดียวกับที่เทรน ====\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# list เก็บค่า ถ้ายังไม่มี\n",
        "try: train_epoch_loss\n",
        "except NameError: train_epoch_loss = []\n",
        "try: val_epoch_loss\n",
        "except NameError: val_epoch_loss = []\n",
        "\n",
        "fig_ep, ax_ep = plt.subplots(figsize=(7,4))\n",
        "(tr_line,) = ax_ep.plot([], [], '-o', label='train loss')\n",
        "(va_line,) = ax_ep.plot([], [], '-s', label='val loss')\n",
        "ax_ep.set_xlabel('Epoch'); ax_ep.set_ylabel('Loss')\n",
        "ax_ep.set_title('Loss per Epoch'); ax_ep.grid(True); ax_ep.legend()\n",
        "\n",
        "# สำคัญ: ใช้ display_id เพื่ออัปเดตกราฟเดิมใน cell เดียว\n",
        "ep_handle = display(fig_ep, display_id=True)\n"
      ],
      "metadata": {
        "id": "wPU5oeaH12OO"
      },
      "id": "wPU5oeaH12OO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Live step-loss plot (สร้างครั้งเดียว) ====\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "class LiveLossPlot:\n",
        "    def __init__(self, title=\"Training Loss (live)\", tail=500, ema_alpha=0.1):\n",
        "        self.tail, self.ema_alpha = tail, ema_alpha\n",
        "        self.fig, self.ax = plt.subplots(figsize=(7,4))\n",
        "        (self.line,) = self.ax.plot([], [], label=\"loss/step\")\n",
        "        (self.ema_line,) = self.ax.plot([], [], ls=\"--\", label=f\"EMA α={ema_alpha}\")\n",
        "        self.ax.set_xlabel(\"Step\"); self.ax.set_ylabel(\"Loss\")\n",
        "        self.ax.set_title(title); self.ax.grid(True); self.ax.legend()\n",
        "        self.handle = display(self.fig, display_id=True)\n",
        "\n",
        "    def update(self, loss_hist):\n",
        "        if not loss_hist: return\n",
        "        x = np.arange(1, len(loss_hist)+1)\n",
        "        self.line.set_data(x, loss_hist)\n",
        "        if len(loss_hist) > 1:\n",
        "            a = self.ema_alpha; ema = [loss_hist[0]]\n",
        "            for v in loss_hist[1:]: ema.append(a*v + (1-a)*ema[-1])\n",
        "            self.ema_line.set_data(x, ema)\n",
        "        tail = loss_hist[-min(self.tail, len(loss_hist)):]\n",
        "        y0, y1 = float(min(tail)), float(max(tail))\n",
        "        if y1 == y0: y1 += 1.0; y0 -= 1.0\n",
        "        m = 0.1*(y1-y0)\n",
        "        self.ax.set_xlim(1, max(50, len(loss_hist)+5))\n",
        "        self.ax.set_ylim(y0-m, y1+m)\n",
        "        self.fig.canvas.draw()\n",
        "        try: self.handle.update(self.fig)\n",
        "        except: display(self.fig)\n",
        "\n",
        "UPDATE_EVERY = 5                  # ปรับความถี่อัปเดตกราฟ\n",
        "live_plot = LiveLossPlot()        # ← สร้างตัวแปรที่คุณส่งเข้า train_one_epoch\n"
      ],
      "metadata": {
        "id": "Zgcz28_R3VdE"
      },
      "id": "Zgcz28_R3VdE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== MNIST-style Epoch Loss Plot (create once) ====\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# lists เก็บค่า loss ราย epoch (ถ้ายังไม่มี)\n",
        "try: train_epoch_loss\n",
        "except NameError: train_epoch_loss = []\n",
        "try: val_epoch_loss\n",
        "except NameError: val_epoch_loss = []\n",
        "\n",
        "# setup figure/lines\n",
        "fig_ep, ax_ep = plt.subplots(figsize=(7,4))\n",
        "(tr_line,) = ax_ep.plot([], [], '-o', label='train loss')\n",
        "(va_line,) = ax_ep.plot([], [], '-s', label='val loss')\n",
        "ax_ep.set_xlabel('Epoch'); ax_ep.set_ylabel('Loss')\n",
        "ax_ep.set_title('Loss per Epoch'); ax_ep.grid(True); ax_ep.legend()\n",
        "\n",
        "# ใช้ display_id เพื่ออัปเดตกราฟเดิมใน cell เดียว (เหมือนตัวอย่าง MNIST)\n",
        "ep_handle = display(fig_ep, display_id=True)\n"
      ],
      "metadata": {
        "id": "DKafr8s6Dd4N"
      },
      "id": "DKafr8s6Dd4N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_epoch_plot():\n",
        "    \"\"\"อัปเดตกราฟราย epoch (train/val) แบบเดียวกับโค้ด MNIST\"\"\"\n",
        "    x = np.arange(1, len(train_epoch_loss) + 1)\n",
        "\n",
        "    # อัปเดตเส้น\n",
        "    tr_line.set_data(x, train_epoch_loss)\n",
        "    va_line.set_data(x, val_epoch_loss)\n",
        "\n",
        "    # ขอบแกน X\n",
        "    ax_ep.set_xlim(1, max(5, len(train_epoch_loss) + 0.5))\n",
        "\n",
        "    # ขอบแกน Y จากค่าที่มีทั้งหมด\n",
        "    if train_epoch_loss or val_epoch_loss:\n",
        "        y_all = (train_epoch_loss or []) + (val_epoch_loss or [])\n",
        "        y_min, y_max = float(min(y_all)), float(max(y_all))\n",
        "        if y_max == y_min:\n",
        "            y_max += 1.0\n",
        "            y_min -= 1.0\n",
        "        margin = 0.1 * (y_max - y_min)\n",
        "        ax_ep.set_ylim(y_min - margin, y_max + margin)\n",
        "\n",
        "    # วาดและอัปเดตเฟรมเดิมใน Colab\n",
        "    fig_ep.canvas.draw()\n",
        "    try:\n",
        "        ep_handle.update(fig_ep)  # ต้องมี display(fig_ep, display_id=True) มาก่อน\n",
        "    except Exception:\n",
        "        display(fig_ep)\n"
      ],
      "metadata": {
        "id": "k2RbxUE_Dgyl"
      },
      "id": "k2RbxUE_Dgyl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fa3c0d4f",
      "metadata": {
        "id": "fa3c0d4f"
      },
      "source": [
        "## 7) Train — วาดกราฟ Loss สดระหว่างเทรน"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f88ad896",
      "metadata": {
        "id": "f88ad896"
      },
      "outputs": [],
      "source": [
        "# ===== Drop-in patch: define missing pieces BEFORE the epoch loop =====\n",
        "import numpy as np\n",
        "import torch, time\n",
        "\n",
        "# 1) Averager (ไว้คำนวณค่าเฉลี่ยราย epoch)\n",
        "class Averager:\n",
        "    def __init__(self): self.reset()\n",
        "    def reset(self): self.total, self.count = 0.0, 0\n",
        "    def update(self, v, n: int = 1): self.total += float(v) * n; self.count += n\n",
        "    @property\n",
        "    def value(self): return self.total / max(1, self.count)\n",
        "\n",
        "# ถ้ายังไม่มีตัวพวกนี้ ให้สร้าง\n",
        "try: train_loss_hist\n",
        "except NameError: train_loss_hist = Averager()\n",
        "try: val_loss_hist\n",
        "except NameError: val_loss_hist   = Averager()\n",
        "try: train_step_loss\n",
        "except NameError: train_step_loss = []\n",
        "try: train_epoch_loss\n",
        "except NameError: train_epoch_loss = []\n",
        "try: val_epoch_loss\n",
        "except NameError: val_epoch_loss   = []\n",
        "try: global_step\n",
        "except NameError: global_step = 0\n",
        "\n",
        "# 2) ฟังก์ชันช่วยปรับ LR\n",
        "def set_lr(opt, lr):\n",
        "    for g in opt.param_groups: g['lr'] = lr\n",
        "\n",
        "def get_warmup_lr(base_lr, step, warmup_steps):\n",
        "    if warmup_steps <= 0: return base_lr\n",
        "    return base_lr * min(1.0, step / float(warmup_steps))\n",
        "\n",
        "# 3) validate แบบ pseudo-loss สำหรับ Faster R-CNN (train-mode + no_grad)\n",
        "@torch.no_grad()\n",
        "def validate(loader, model):\n",
        "    model.train()\n",
        "    val_loss_hist.reset()\n",
        "    for images, targets in loader:\n",
        "        images  = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss_sum  = sum(loss for loss in loss_dict.values())\n",
        "        val_loss_hist.update(loss_sum.item())\n",
        "    return val_loss_hist.value\n",
        "\n",
        "# 4) train 1 epoch (log ไปที่ Comet แบบรายสเต็ป)\n",
        "def train_one_epoch(loader, model, epoch: int):\n",
        "    model.train()\n",
        "    train_loss_hist.reset()\n",
        "    global global_step\n",
        "\n",
        "    num_batches = len(loader)\n",
        "    print(f\"[train] batches: {num_batches}, batch_size: {BATCH_SIZE}\")\n",
        "\n",
        "    t_epoch0 = time.time()\n",
        "\n",
        "    for step, (images, targets) in enumerate(loader, start=1):\n",
        "        t0 = time.time()\n",
        "\n",
        "        images  = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # warmup LR\n",
        "        warm_lr = get_warmup_lr(LR, global_step, WARMUP_STEPS)\n",
        "        set_lr(optimizer, warm_lr)\n",
        "\n",
        "        # forward/backward\n",
        "        loss_dict = model(images, targets)\n",
        "        losses    = sum(loss for loss in loss_dict.values())\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # stat\n",
        "        loss_val = float(losses.item())\n",
        "        train_loss_hist.update(loss_val)\n",
        "        train_step_loss.append(loss_val)\n",
        "        global_step += 1\n",
        "\n",
        "        # --- อัปเดตกราฟใน Colab ---\n",
        "        if live_plot is not None and (step % UPDATE_EVERY) == 0:\n",
        "            live_plot.update(train_step_loss)\n",
        "\n",
        "        # ==== Comet: log metric รายสเต็ป ====\n",
        "        experiment.log_metric(\"train/step_loss\", loss_val, step=global_step)\n",
        "        experiment.log_metric(\"lr\", optimizer.param_groups[0]['lr'], step=global_step)\n",
        "\n",
        "        # timing/log\n",
        "        t1 = time.time()\n",
        "        step_time = t1 - t0\n",
        "        avg_step_time = (t1 - t_epoch0) / step\n",
        "        eta = avg_step_time * (num_batches - step)\n",
        "        if (step % 10) == 1 or step == 1:\n",
        "            mem = (torch.cuda.memory_allocated()/1e9) if torch.cuda.is_available() else 0.0\n",
        "            print(f\"[epoch {epoch} step {step}/{num_batches}] \"\n",
        "                  f\"loss={loss_val:.3f} \"\n",
        "                  f\"step_time={step_time:.2f}s avg={avg_step_time:.2f}s ETA={eta/60:.1f}m \"\n",
        "                  f\"lr={optimizer.param_groups[0]['lr']:.6f} \"\n",
        "                  f\"gpu_mem~{mem:.2f}GB\")\n",
        "\n",
        "    return train_loss_hist.value\n",
        "\n",
        "# 5) ตัวอย่าง SaveBestModel และ save_model (เหมือนเดิม)\n",
        "class SaveBestModel:\n",
        "    def __init__(self):\n",
        "        self.best = float(\"inf\")\n",
        "    def __call__(self, current_val_loss, epoch, model, optimizer, scheduler):\n",
        "        if current_val_loss < self.best:\n",
        "            self.best = current_val_loss\n",
        "            torch.save({\n",
        "                \"epoch\": epoch,\n",
        "                \"model\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "                \"scheduler\": scheduler.state_dict() if scheduler else None,\n",
        "                \"best_val_loss\": self.best,\n",
        "            }, OUTPUT_DIR / \"best_model.pth\")\n",
        "            print(f\">>> Saved best (val_loss={current_val_loss:.4f}) at epoch {epoch+1}\")\n",
        "            # แนบไฟล์ไปที่ Comet ด้วย (สะดวกเวลารีวิว)\n",
        "            try:\n",
        "                experiment.log_asset(str(OUTPUT_DIR / \"best_model.pth\"), step=epoch+1)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "def save_model(epoch, model, optimizer, scheduler):\n",
        "    path = OUTPUT_DIR / f\"epoch_{epoch+1}.pth\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"scheduler\": scheduler.state_dict() if scheduler else None,\n",
        "    }, path)\n",
        "    # แนบไฟล์ checkpoint ใน Comet (optional)\n",
        "    try:\n",
        "        experiment.log_asset(str(path), step=epoch+1)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# ====== ลูปหลักแบบที่ต้องการ ======\n",
        "save_best_model = SaveBestModel()\n",
        "\n",
        "NUM_EPOCHS = EPOCHS  # หรือกำหนดเลขคงที่\n",
        "start_epoch = 0\n",
        "\n",
        "for ep in range(start_epoch, NUM_EPOCHS):\n",
        "    print(f\"\\nEPOCH {ep+1} of {NUM_EPOCHS}\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    train_mean = train_one_epoch(train_loader, model, epoch=ep+1)   # ไม่ต้องส่ง live_plot\n",
        "    val_mean   = validate(val_loader, model)\n",
        "    elapsed = time.time() - t0\n",
        "\n",
        "    train_epoch_loss.append(train_mean)\n",
        "    val_epoch_loss.append(val_mean)\n",
        "    update_epoch_plot()  # <<== จุดสำคัญ\n",
        "\n",
        "\n",
        "    # ==== Comet: log metric ราย epoch ====\n",
        "    experiment.log_metrics({\n",
        "        \"epoch/train_loss\": train_mean,\n",
        "        \"epoch/val_loss\": val_mean,\n",
        "    }, step=ep+1, epoch=ep+1)\n",
        "\n",
        "    # แสดง LR\n",
        "    try:\n",
        "        lr_now = scheduler.get_last_lr() if scheduler else [g['lr'] for g in optimizer.param_groups]\n",
        "    except Exception:\n",
        "        lr_now = [g['lr'] for g in optimizer.param_groups]\n",
        "    print(f\"Epoch #{ep+1} train loss: {train_mean:.3f} | val loss: {val_mean:.3f} | lr: {lr_now} | time: {elapsed:.1f}s\")\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "    save_best_model(val_mean, ep, model, optimizer, scheduler)\n",
        "    save_model(ep, model, optimizer, scheduler)\n",
        "\n",
        "# ปิด experiment เมื่อจบ\n",
        "experiment.end()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}