{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttntbn/Deep-Learning/blob/main/helmet_frcnn_clean_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22801550",
      "metadata": {
        "id": "22801550"
      },
      "source": [
        "\n",
        "# Helmet Detection using Faster R-CNN â€” Clean Notebook\n",
        "A cleaned, minimal-yet-complete training notebook for Faster R-CNN on a VOC-XML style helmet dataset.\n",
        "\n",
        "**What you get**\n",
        "- Simple hyperparam block\n",
        "- Clean dataset loader (VOC-XML)\n",
        "- Robust DataLoader (Drive-friendly)\n",
        "- Warmup LR + optional schedulers\n",
        "- MNIST-style epoch-loss plot (in-cell, real-time)\n",
        "- Optional Comet logging (toggle)\n",
        "- Best checkpoint + per-epoch checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca9977b",
      "metadata": {
        "id": "eca9977b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0a83bf-81db-45bf-c43e-bb0fe8ff1e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/boonyapon-boontub-0272/helmet-fasterrcnn/824a53f5c7db4579af4f3c6499051ef3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comet enabled.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === (Optional) Enable Comet: set `ENABLE_COMET=True` and fill API/WORKSPACE if you want logging ===\n",
        "ENABLE_COMET = True  # set False to disable\n",
        "COMET_API_KEY   = \"KlDdmMhprhNGWTot1PPhnMo4u\"        # required if ENABLE_COMET=True\n",
        "COMET_WORKSPACE = \"boonyapon-boontub-0272\"      # e.g., \"boonyapon-boontub-0272\"\n",
        "COMET_PROJECT   = \"helmet-fasterrcnn\"\n",
        "\n",
        "if ENABLE_COMET:\n",
        "    try:\n",
        "        # Comet should be imported before torch for full auto logging;\n",
        "        # we do our own explicit logging so this is mostly informational.\n",
        "        import sys, subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"comet-ml\"], check=False)\n",
        "        import os\n",
        "        from comet_ml import Experiment\n",
        "        os.environ[\"COMET_API_KEY\"]      = COMET_API_KEY\n",
        "        os.environ[\"COMET_WORKSPACE\"]    = COMET_WORKSPACE\n",
        "        os.environ[\"COMET_PROJECT_NAME\"] = COMET_PROJECT\n",
        "        experiment = Experiment(\n",
        "            api_key=os.getenv(\"COMET_API_KEY\"),\n",
        "            workspace=os.getenv(\"COMET_WORKSPACE\"),\n",
        "            project_name=os.getenv(\"COMET_PROJECT_NAME\"),\n",
        "            auto_metric_logging=False,\n",
        "            auto_param_logging=False,\n",
        "            auto_output_logging=\"simple\",\n",
        "        )\n",
        "        experiment.set_name(\"fasterrcnn-helmet-run\")\n",
        "        print(\"Comet enabled.\")\n",
        "    except Exception as e:\n",
        "        print(\"[WARN] Comet init failed -> turning off. Reason:\", e)\n",
        "        ENABLE_COMET = False\n",
        "        experiment = None\n",
        "else:\n",
        "    experiment = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df14c563",
      "metadata": {
        "id": "df14c563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bced98d-3c54-4b81-e2c3-f41e1d80f2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==== Imports & setup ====\n",
        "import os, time, random, xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import torchvision\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # tolerate truncated images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# speed up convs on CUDA\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f2b31b",
      "metadata": {
        "id": "67f2b31b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== Hyperparameters ====\n",
        "# Training\n",
        "EPOCHS        = 15\n",
        "BATCH_SIZE    = 8\n",
        "LR            = 5e-4\n",
        "WEIGHT_DECAY  = 1e-4\n",
        "MOMENTUM      = 0.9\n",
        "WARMUP_STEPS  = 500\n",
        "\n",
        "# Scheduler\n",
        "LR_SCHEDULER  = \"multistep\"   # [\"none\",\"multistep\",\"cosine\"]\n",
        "MILESTONES    = [10, 13]\n",
        "GAMMA         = 0.1\n",
        "COSINE_TMAX   = EPOCHS\n",
        "ETA_MIN       = 1e-6\n",
        "\n",
        "# Data aug\n",
        "H_FLIP_PROB   = 0.5\n",
        "RAND_RESIZE   = (640, 1024)   # min, max shorter side\n",
        "COLOR_JITTER  = True\n",
        "\n",
        "# Paths (set this to your dataset root)\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/helmet_dataset\")  # change if needed\n",
        "TRAIN_IMG = DATA_ROOT / \"train/images\"\n",
        "TRAIN_ANN = DATA_ROOT / \"train/annotations\"\n",
        "VAL_IMG   = DATA_ROOT / \"val/images\"\n",
        "VAL_ANN   = DATA_ROOT / \"val/annotations\"\n",
        "\n",
        "# Output\n",
        "OUTPUT_DIR = Path(\"./outputs_frcnn_clean\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c853c222",
      "metadata": {
        "id": "c853c222"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== Utilities ====\n",
        "\n",
        "class Averager:\n",
        "    def __init__(self): self.reset()\n",
        "    def reset(self): self.total, self.count = 0.0, 0\n",
        "    def update(self, v, n: int = 1): self.total += float(v) * n; self.count += n\n",
        "    @property\n",
        "    def value(self): return self.total / max(1, self.count)\n",
        "\n",
        "def set_lr(opt, lr):\n",
        "    for g in opt.param_groups: g['lr'] = lr\n",
        "\n",
        "def get_warmup_lr(base_lr, step, warmup_steps):\n",
        "    if warmup_steps <= 0: return base_lr\n",
        "    return base_lr * min(1.0, step / float(warmup_steps))\n",
        "\n",
        "def collate_fn(batch):\n",
        "    imgs, tgts = list(zip(*batch))\n",
        "    return list(imgs), list(tgts)\n",
        "\n",
        "def make_transforms(train: bool):\n",
        "    ts = []\n",
        "    ts.append(T.ToTensor())\n",
        "    if train:\n",
        "        if H_FLIP_PROB > 0:\n",
        "            ts.append(T.RandomHorizontalFlip(p=H_FLIP_PROB))\n",
        "        if COLOR_JITTER:\n",
        "            ts.append(T.ColorJitter(0.2, 0.2, 0.2, 0.1))\n",
        "    return T.Compose(ts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f96504",
      "metadata": {
        "id": "d9f96504"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== Dataset (VOC XML) ====\n",
        "\n",
        "# Classes (first is background index 0; for torchvision Faster R-CNN you pass labels >=1)\n",
        "CLASSES = [\"__background__\", \"helmet\"]  # adjust if you have multiple classes\n",
        "\n",
        "def _read_voc_xml(xml_path: Path, class_to_idx: Dict[str,int]):\n",
        "    boxes, labels = [], []\n",
        "    root = ET.parse(str(xml_path)).getroot()\n",
        "    for obj in root.findall(\"object\"):\n",
        "        name = obj.find(\"name\").text\n",
        "        if name not in class_to_idx:\n",
        "            continue\n",
        "        bnd = obj.find(\"bndbox\")\n",
        "        xmin = float(bnd.find(\"xmin\").text)\n",
        "        ymin = float(bnd.find(\"ymin\").text)\n",
        "        xmax = float(bnd.find(\"xmax\").text)\n",
        "        ymax = float(bnd.find(\"ymax\").text)\n",
        "        boxes.append([xmin, ymin, xmax, ymax])\n",
        "        labels.append(class_to_idx[name])\n",
        "    return boxes, labels\n",
        "\n",
        "class HelmetVOCDataset(Dataset):\n",
        "    def __init__(self, img_dir: Path, ann_dir: Path, classes, transforms=None):\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.ann_dir = Path(ann_dir)\n",
        "        self.transforms = transforms\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = {c:i for i,c in enumerate(self.classes)}\n",
        "        assert self.img_dir.is_dir() and self.ann_dir.is_dir(), \"Image/Annotation dirs not found\"\n",
        "\n",
        "        exts = {\".jpg\",\".jpeg\",\".png\"}\n",
        "        items = []\n",
        "        for p in sorted(self.img_dir.iterdir()):\n",
        "            if p.suffix.lower() in exts and p.is_file():\n",
        "                xml = self.ann_dir / (p.stem + \".xml\")\n",
        "                if xml.exists():\n",
        "                    items.append((p, xml))\n",
        "        if not items:\n",
        "            raise RuntimeError(f\"No image-xml pairs under {self.img_dir} & {self.ann_dir}\")\n",
        "        self.items = items\n",
        "\n",
        "    def __len__(self): return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, xml_path = self.items[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        try:\n",
        "            boxes, labels = _read_voc_xml(xml_path, self.class_to_idx)\n",
        "        except ET.ParseError as e:\n",
        "            boxes, labels = [], []\n",
        "            print(\"[WARN] Bad XML, empty target:\", xml_path, e)\n",
        "\n",
        "        boxes  = torch.as_tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0,4), dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)  if labels else torch.zeros((0,), dtype=torch.int64)\n",
        "        target = {\"boxes\": boxes, \"labels\": labels, \"image_id\": torch.tensor([idx])}\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "        return img, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1d00028",
      "metadata": {
        "id": "b1d00028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9c2bae66-c63d-4ebc-9146-2cb2e0093065"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Check DATA_ROOT paths",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4012187328.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ==== Build datasets & loaders ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mTRAIN_IMG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mTRAIN_ANN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mVAL_IMG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mVAL_ANN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Check DATA_ROOT paths\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHelmetVOCDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_IMG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_ANN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mHelmetVOCDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_IMG\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mVAL_ANN\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mCLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Check DATA_ROOT paths"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==== Build datasets & loaders ====\n",
        "assert TRAIN_IMG.exists() and TRAIN_ANN.exists() and VAL_IMG.exists() and VAL_ANN.exists(), \"Check DATA_ROOT paths\"\n",
        "\n",
        "train_ds = HelmetVOCDataset(TRAIN_IMG, TRAIN_ANN, CLASSES, transforms=make_transforms(train=True))\n",
        "val_ds   = HelmetVOCDataset(VAL_IMG,   VAL_ANN,   CLASSES, transforms=make_transforms(train=False))\n",
        "\n",
        "# Start with num_workers=0 to reveal dataset errors clearly (Drive-friendly)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=0, collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False,\n",
        "                          num_workers=0, collate_fn=collate_fn)\n",
        "\n",
        "print(\"train/val sizes:\", len(train_ds), len(val_ds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a8e5c78",
      "metadata": {
        "id": "6a8e5c78"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== Model: Faster R-CNN (ResNet50-FPN) ====\n",
        "import torchvision\n",
        "num_classes = len(CLASSES)\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "# Optimizer & Scheduler\n",
        "optimizer = torch.optim.SGD([p for p in model.parameters() if p.requires_grad],\n",
        "                            lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "if LR_SCHEDULER == \"multistep\":\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES, gamma=GAMMA)\n",
        "elif LR_SCHEDULER == \"cosine\":\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=COSINE_TMAX, eta_min=ETA_MIN)\n",
        "else:\n",
        "    scheduler = None\n",
        "\n",
        "# Comet params\n",
        "if ENABLE_COMET and ('experiment' in globals()) and (experiment is not None):\n",
        "    experiment.log_parameters({\n",
        "        \"EPOCHS\": EPOCHS, \"BATCH_SIZE\": BATCH_SIZE, \"LR\": LR,\n",
        "        \"WEIGHT_DECAY\": WEIGHT_DECAY, \"MOMENTUM\": MOMENTUM,\n",
        "        \"WARMUP_STEPS\": WARMUP_STEPS, \"LR_SCHEDULER\": LR_SCHEDULER,\n",
        "        \"MILESTONES\": MILESTONES, \"GAMMA\": GAMMA,\n",
        "        \"COSINE_TMAX\": COSINE_TMAX, \"ETA_MIN\": ETA_MIN,\n",
        "        \"RAND_RESIZE\": str(RAND_RESIZE), \"H_FLIP_PROB\": H_FLIP_PROB,\n",
        "        \"COLOR_JITTER\": COLOR_JITTER, \"SEED\": SEED,\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66ef115",
      "metadata": {
        "id": "e66ef115"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== Validate / Train ====\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Averager:\n",
        "    def __init__(self): self.reset()\n",
        "    def reset(self): self.total, self.count = 0.0, 0\n",
        "    def update(self, v, n: int = 1): self.total += float(v) * n; self.count += n\n",
        "    @property\n",
        "    def value(self): return self.total / max(1, self.count)\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate(loader, model):\n",
        "    model.train()  # detection losses computed in train()\n",
        "    loss_hist = Averager()\n",
        "    for images, targets in loader:\n",
        "        images  = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        loss_sum  = sum(loss for loss in loss_dict.values())\n",
        "        loss_hist.update(loss_sum.item())\n",
        "    return loss_hist.value\n",
        "\n",
        "global_step = 0\n",
        "\n",
        "def set_lr(opt, lr):\n",
        "    for g in opt.param_groups:\n",
        "        g['lr'] = lr\n",
        "\n",
        "def get_warmup_lr(base_lr, step, warmup_steps):\n",
        "    if warmup_steps <= 0: return base_lr\n",
        "    return base_lr * min(1.0, step / float(warmup_steps))\n",
        "\n",
        "def train_one_epoch(loader, model, epoch: int):\n",
        "    global global_step\n",
        "    model.train()\n",
        "    loss_hist = Averager()\n",
        "\n",
        "    num_batches = len(loader)\n",
        "    print(f\"[train] epoch {epoch} | batches: {num_batches}, batch_size: {BATCH_SIZE}\")\n",
        "\n",
        "    t_epoch0 = time.time()\n",
        "    for step, (images, targets) in enumerate(loader, start=1):\n",
        "        t0 = time.time()\n",
        "\n",
        "        images  = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        # Warmup LR\n",
        "        warm_lr = get_warmup_lr(LR, global_step, WARMUP_STEPS)\n",
        "        set_lr(optimizer, warm_lr)\n",
        "\n",
        "        # Forward/backward\n",
        "        loss_dict = model(images, targets)\n",
        "        losses    = sum(loss for loss in loss_dict.values())\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val = float(losses.item())\n",
        "        loss_hist.update(loss_val)\n",
        "        global_step += 1\n",
        "\n",
        "        # Comet (step-level)\n",
        "        if ENABLE_COMET and ('experiment' in globals()) and (experiment is not None):\n",
        "            experiment.log_metric(\"train/step_loss\", loss_val, step=global_step)\n",
        "            experiment.log_metric(\"lr\", optimizer.param_groups[0]['lr'], step=global_step)\n",
        "\n",
        "        # Friendly log\n",
        "        if (step % 10) == 1 or step == 1:\n",
        "            step_time = time.time() - t0\n",
        "            avg_step_time = (time.time() - t_epoch0) / step\n",
        "            eta = avg_step_time * (num_batches - step)\n",
        "            mem = (torch.cuda.memory_allocated()/1e9) if torch.cuda.is_available() else 0.0\n",
        "            print(f\"  [step {step:4d}/{num_batches}] \"\n",
        "                  f\"loss={loss_val:.3f}  step:{step_time:.2f}s  ETA:{eta/60:.1f}m  \"\n",
        "                  f\"lr={optimizer.param_groups[0]['lr']:.6f}  gpu~{mem:.2f}GB\")\n",
        "\n",
        "    return loss_hist.value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e592247",
      "metadata": {
        "id": "5e592247"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== MNIST-style Epoch Loss Plot ====\n",
        "train_epoch_loss, val_epoch_loss = [], []\n",
        "\n",
        "fig_ep, ax_ep = plt.subplots(figsize=(7,4))\n",
        "(tr_line,) = ax_ep.plot([], [], '-o', label='train loss')\n",
        "(va_line,) = ax_ep.plot([], [], '-s', label='val loss')\n",
        "ax_ep.set_xlabel('Epoch'); ax_ep.set_ylabel('Loss')\n",
        "ax_ep.set_title('Loss per Epoch'); ax_ep.grid(True); ax_ep.legend()\n",
        "ep_handle = display(fig_ep, display_id=True)\n",
        "\n",
        "def update_epoch_plot():\n",
        "    x = np.arange(1, len(train_epoch_loss) + 1)\n",
        "    tr_line.set_data(x, train_epoch_loss)\n",
        "    va_line.set_data(x, val_epoch_loss)\n",
        "    ax_ep.set_xlim(1, max(5, len(train_epoch_loss) + 0.5))\n",
        "    if train_epoch_loss or val_epoch_loss:\n",
        "        y_all = (train_epoch_loss or []) + (val_epoch_loss or [])\n",
        "        y0, y1 = float(min(y_all)), float(max(y_all))\n",
        "        if y1 == y0: y1 += 1.0; y0 -= 1.0\n",
        "        m = 0.1*(y1 - y0)\n",
        "        ax_ep.set_ylim(y0 - m, y1 + m)\n",
        "    fig_ep.canvas.draw()\n",
        "    try: ep_handle.update(fig_ep)\n",
        "    except: display(fig_ep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2fb7ec1",
      "metadata": {
        "id": "d2fb7ec1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==== Save helpers + Main loop ====\n",
        "def save_best_model(val_loss, best_val, epoch):\n",
        "    if val_loss < best_val[0]:\n",
        "        best_val[0] = val_loss\n",
        "        path = OUTPUT_DIR / \"best_model.pth\"\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"scheduler\": scheduler.state_dict() if scheduler else None,\n",
        "            \"best_val_loss\": best_val[0],\n",
        "        }, path)\n",
        "        print(f\">>> Saved BEST (val_loss={val_loss:.4f}) at epoch {epoch}\")\n",
        "        if ENABLE_COMET and ('experiment' in globals()) and (experiment is not None):\n",
        "            try: experiment.log_asset(str(path), step=epoch)\n",
        "            except Exception: pass\n",
        "\n",
        "def save_epoch_model(epoch):\n",
        "    path = OUTPUT_DIR / f\"epoch_{epoch}.pth\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"scheduler\": scheduler.state_dict() if scheduler else None,\n",
        "    }, path)\n",
        "    if ENABLE_COMET and ('experiment' in globals()) and (experiment is not None):\n",
        "        try: experiment.log_asset(str(path), step=epoch)\n",
        "        except Exception: pass\n",
        "\n",
        "start_epoch = 1\n",
        "NUM_EPOCHS = EPOCHS\n",
        "best_val = [float(\"inf\")]\n",
        "\n",
        "for ep in range(start_epoch, NUM_EPOCHS + 1):\n",
        "    print(f\"\\nEPOCH {ep} of {NUM_EPOCHS}\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    train_mean = train_one_epoch(train_loader, model, epoch=ep)\n",
        "    val_mean   = validate(val_loader, model)\n",
        "    elapsed    = time.time() - t0\n",
        "\n",
        "    # Record & plot\n",
        "    train_epoch_loss.append(train_mean)\n",
        "    val_epoch_loss.append(val_mean)\n",
        "    update_epoch_plot()\n",
        "\n",
        "    # Scheduler step (per-epoch)\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "    # Comet (epoch-level)\n",
        "    if ENABLE_COMET and ('experiment' in globals()) and (experiment is not None):\n",
        "        experiment.log_metrics({\n",
        "            \"epoch/train_loss\": train_mean,\n",
        "            \"epoch/val_loss\": val_mean,\n",
        "        }, step=ep, epoch=ep)\n",
        "\n",
        "    print(f\"Epoch #{ep:02d} | train={train_mean:.3f}  val={val_mean:.3f}  time={elapsed:.1f}s\")\n",
        "\n",
        "    # Save\n",
        "    save_best_model(val_mean, best_val, ep)\n",
        "    save_epoch_model(ep)\n",
        "\n",
        "if ENABLE_COMET and ('experiment' in globals()) and (experiment is not None):\n",
        "    experiment.end()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}